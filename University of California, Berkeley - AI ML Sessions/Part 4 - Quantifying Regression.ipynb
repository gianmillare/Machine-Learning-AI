{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Quantifying Regression\n",
    "\n",
    "Focus is to find a way to quanitfy an error in the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dependencies\n",
    "from sklearn.datasets import make_regression\n",
    "from sklearn.linear_model import LinearRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(20, 1)\n",
      "(20,)\n"
     ]
    }
   ],
   "source": [
    "# Code used to generate some random data in linear regression models\n",
    "\n",
    "X, y = make_regression(n_samples=20, n_features=1, random_state=0, noise=4, bias=100.0)\n",
    "print(X.shape)\n",
    "print(y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LinearRegression()"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create the model and fit it\n",
    "model = LinearRegression()\n",
    "model.fit(X, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Quantifying our Model: Finding our 'Loss'\n",
    "\n",
    "* Mean Squared Error (MSE)\n",
    "* R2 Score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Squared Error: 11.933040779746149\n",
      "R-Squared: 0.903603363418708\n"
     ]
    }
   ],
   "source": [
    "# We will quantify how well our model does using r2 and MSE\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "\n",
    "# first use a model to predict\n",
    "predicted = model.predict(X)\n",
    "\n",
    "# Score the prediction with MSE and R2\n",
    "mse = mean_squared_error(y, predicted)\n",
    "r2 = r2_score(y, predicted)\n",
    "\n",
    "print(\"Mean Squared Error: {}\".format(mse))\n",
    "print(\"R-Squared: {}\".format(r2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### What is Mean Squared Error (technical)\n",
    "\n",
    "NOTE: \"(y, predicted)\" - y is our actual (provided) values. and predicted is a result of model.predict(X)  \n",
    "\n",
    "Mean Squared Error - take all y and predicted, subtract them, then square them. Then find the mean of all those squares. This is the average the square between the actual and predicted values."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### What is R Squared?\n",
    "\n",
    "R2 - how much of a variance did the regression capture over the actual values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bottom Line:\n",
    "\n",
    "A \"good\" MSE score will be close to zero while a \"good\" R squared score will be close to 1.\n",
    "\n",
    "R squared is the default scoring for many of the Sklearn models.\n",
    "\n",
    "The \"best\" way to test your model is to input your own made up values and checking how accurate / how big of an error you receive."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.903603363418708"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Continue...\n",
    "\n",
    "# model.score gives R2\n",
    "model.score(X, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Validation\n",
    "\n",
    "How well does the model perform on new data?  \n",
    "One approach is to split the data into training data and test data.  \n",
    "Train (fit) the data using the training data, then score and validate the model using testing data.  \n",
    "Sklearn provides a mechanism for doing this."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing and Training Data\n",
    "In order to quantify our model against new data, we often split the data into training and testing data. Then the model is fit to the training data and scored by the testing data. Use Sklearn to split the data into training and testing sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dependency to split test and training data \n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(20, 1)\n",
      "(15, 1) (15,)\n"
     ]
    }
   ],
   "source": [
    "print(X.shape)\n",
    "print(X_train.shape, y_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.3130677 ]\n",
      " [ 0.12167502]\n",
      " [-0.85409574]\n",
      " [ 0.44386323]\n",
      " [ 0.76103773]\n",
      " [ 1.86755799]\n",
      " [ 0.97873798]\n",
      " [ 1.49407907]\n",
      " [ 1.76405235]\n",
      " [-0.97727788]\n",
      " [ 1.45427351]\n",
      " [-0.20515826]\n",
      " [ 0.95008842]\n",
      " [ 0.14404357]\n",
      " [-0.10321885]]\n",
      "[100.14472604 107.32614044  90.31520078 113.51286154 106.59661396\n",
      " 125.80345967 107.77654399 122.11966081 125.42202601  92.04796546\n",
      " 121.44454917  95.20896669 112.28760019 104.3306721  104.37128562]\n"
     ]
    }
   ],
   "source": [
    "print(X_train) # 2d array \"array of arrays\"\n",
    "print(y_train) # 1d array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LinearRegression()"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Then fit (train) the model using the training data X_train y_train\n",
    "model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9252522435044104"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Then score the data using testing data X_test y_test\n",
    "model.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In other words, this model acheived a score of 92.5% accuracy on the test data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
