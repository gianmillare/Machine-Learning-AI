{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1a775a21",
   "metadata": {},
   "source": [
    "# Smartphone Activity Detector - Deep Learning Models\n",
    "\n",
    "[Source](http://archive.ics.uci.edu/ml/datasets/Smartphone-Based+Recognition+of+Human+Activities+and+Postural+Transitions)  \n",
    "\n",
    "Objective: Predict movements and activity based on smartphone sensor data. Note: The data is already scaled and training and testing data is split into 4 separate files."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "116fa208",
   "metadata": {},
   "source": [
    "### Note the labels (y outputs) are interpreted as the below\n",
    "\n",
    "* 1 WALKING\n",
    "* 2 WALKING_UPSTAIRS\n",
    "* 3 WALKING_DOWNSTAIRS\n",
    "* 4 SITTING\n",
    "* 5 STANDING\n",
    "* 6 LAYING\n",
    "* 7 STAND_TO_SIT\n",
    "* 8 SIT_TO_STAND\n",
    "* 9 SIT_TO_LIE\n",
    "* 10 LIE_TO_SIT\n",
    "* 11 STAND_TO_LIE\n",
    "* 12 LIE_TO_STAND"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "650f4640",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1: Import Dependencies\n",
    "\n",
    "import tensorflow as tf\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.utils import to_categorical\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "6d817c29",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 2: Get the data\n",
    "X_train = os.path.join(\"resources\", \"smartphone_x_train.txt\")\n",
    "y_train = os.path.join(\"resources\", \"smartphone_y_train.txt\")\n",
    "X_test = os.path.join(\"resources\", \"smartphone_x_test.txt\")\n",
    "y_test = os.path.join(\"resources\", \"smartphone_y_test.txt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03fdc65c",
   "metadata": {},
   "source": [
    "### Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "695e54dc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>551</th>\n",
       "      <th>552</th>\n",
       "      <th>553</th>\n",
       "      <th>554</th>\n",
       "      <th>555</th>\n",
       "      <th>556</th>\n",
       "      <th>557</th>\n",
       "      <th>558</th>\n",
       "      <th>559</th>\n",
       "      <th>560</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.039480</td>\n",
       "      <td>-0.002131</td>\n",
       "      <td>-0.029067</td>\n",
       "      <td>-0.998348</td>\n",
       "      <td>-0.982945</td>\n",
       "      <td>-0.971273</td>\n",
       "      <td>-0.998702</td>\n",
       "      <td>-0.983315</td>\n",
       "      <td>-0.974000</td>\n",
       "      <td>-0.802537</td>\n",
       "      <td>...</td>\n",
       "      <td>0.202804</td>\n",
       "      <td>-0.603199</td>\n",
       "      <td>-0.860677</td>\n",
       "      <td>0.053477</td>\n",
       "      <td>-0.007435</td>\n",
       "      <td>-0.732626</td>\n",
       "      <td>0.703511</td>\n",
       "      <td>-0.845092</td>\n",
       "      <td>0.180261</td>\n",
       "      <td>-0.047436</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.039978</td>\n",
       "      <td>-0.005153</td>\n",
       "      <td>-0.022651</td>\n",
       "      <td>-0.995482</td>\n",
       "      <td>-0.977314</td>\n",
       "      <td>-0.984760</td>\n",
       "      <td>-0.996415</td>\n",
       "      <td>-0.975835</td>\n",
       "      <td>-0.985973</td>\n",
       "      <td>-0.798477</td>\n",
       "      <td>...</td>\n",
       "      <td>0.440079</td>\n",
       "      <td>-0.404427</td>\n",
       "      <td>-0.761847</td>\n",
       "      <td>-0.118559</td>\n",
       "      <td>0.177899</td>\n",
       "      <td>0.100699</td>\n",
       "      <td>0.808529</td>\n",
       "      <td>-0.849230</td>\n",
       "      <td>0.180610</td>\n",
       "      <td>-0.042271</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.039785</td>\n",
       "      <td>-0.011809</td>\n",
       "      <td>-0.028916</td>\n",
       "      <td>-0.996194</td>\n",
       "      <td>-0.988569</td>\n",
       "      <td>-0.993256</td>\n",
       "      <td>-0.996994</td>\n",
       "      <td>-0.988526</td>\n",
       "      <td>-0.993135</td>\n",
       "      <td>-0.798477</td>\n",
       "      <td>...</td>\n",
       "      <td>0.430891</td>\n",
       "      <td>-0.138373</td>\n",
       "      <td>-0.491604</td>\n",
       "      <td>-0.036788</td>\n",
       "      <td>-0.012892</td>\n",
       "      <td>0.640011</td>\n",
       "      <td>-0.485366</td>\n",
       "      <td>-0.848947</td>\n",
       "      <td>0.181907</td>\n",
       "      <td>-0.040826</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.038758</td>\n",
       "      <td>-0.002289</td>\n",
       "      <td>-0.023863</td>\n",
       "      <td>-0.998241</td>\n",
       "      <td>-0.986774</td>\n",
       "      <td>-0.993115</td>\n",
       "      <td>-0.998216</td>\n",
       "      <td>-0.986479</td>\n",
       "      <td>-0.993825</td>\n",
       "      <td>-0.801982</td>\n",
       "      <td>...</td>\n",
       "      <td>0.137735</td>\n",
       "      <td>-0.366214</td>\n",
       "      <td>-0.702490</td>\n",
       "      <td>0.123320</td>\n",
       "      <td>0.122542</td>\n",
       "      <td>0.693578</td>\n",
       "      <td>-0.615971</td>\n",
       "      <td>-0.848164</td>\n",
       "      <td>0.185124</td>\n",
       "      <td>-0.037080</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.038988</td>\n",
       "      <td>0.004109</td>\n",
       "      <td>-0.017340</td>\n",
       "      <td>-0.997438</td>\n",
       "      <td>-0.993485</td>\n",
       "      <td>-0.996692</td>\n",
       "      <td>-0.997522</td>\n",
       "      <td>-0.993494</td>\n",
       "      <td>-0.996916</td>\n",
       "      <td>-0.801982</td>\n",
       "      <td>...</td>\n",
       "      <td>0.074999</td>\n",
       "      <td>-0.554902</td>\n",
       "      <td>-0.844224</td>\n",
       "      <td>0.082632</td>\n",
       "      <td>-0.143439</td>\n",
       "      <td>0.275041</td>\n",
       "      <td>-0.368224</td>\n",
       "      <td>-0.849927</td>\n",
       "      <td>0.184795</td>\n",
       "      <td>-0.035326</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 561 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        0         1         2         3         4         5         6    \\\n",
       "0  0.039480 -0.002131 -0.029067 -0.998348 -0.982945 -0.971273 -0.998702   \n",
       "1  0.039978 -0.005153 -0.022651 -0.995482 -0.977314 -0.984760 -0.996415   \n",
       "2  0.039785 -0.011809 -0.028916 -0.996194 -0.988569 -0.993256 -0.996994   \n",
       "3  0.038758 -0.002289 -0.023863 -0.998241 -0.986774 -0.993115 -0.998216   \n",
       "4  0.038988  0.004109 -0.017340 -0.997438 -0.993485 -0.996692 -0.997522   \n",
       "\n",
       "        7         8         9    ...       551       552       553       554  \\\n",
       "0 -0.983315 -0.974000 -0.802537  ...  0.202804 -0.603199 -0.860677  0.053477   \n",
       "1 -0.975835 -0.985973 -0.798477  ...  0.440079 -0.404427 -0.761847 -0.118559   \n",
       "2 -0.988526 -0.993135 -0.798477  ...  0.430891 -0.138373 -0.491604 -0.036788   \n",
       "3 -0.986479 -0.993825 -0.801982  ...  0.137735 -0.366214 -0.702490  0.123320   \n",
       "4 -0.993494 -0.996916 -0.801982  ...  0.074999 -0.554902 -0.844224  0.082632   \n",
       "\n",
       "        555       556       557       558       559       560  \n",
       "0 -0.007435 -0.732626  0.703511 -0.845092  0.180261 -0.047436  \n",
       "1  0.177899  0.100699  0.808529 -0.849230  0.180610 -0.042271  \n",
       "2 -0.012892  0.640011 -0.485366 -0.848947  0.181907 -0.040826  \n",
       "3  0.122542  0.693578 -0.615971 -0.848164  0.185124 -0.037080  \n",
       "4 -0.143439  0.275041 -0.368224 -0.849927  0.184795 -0.035326  \n",
       "\n",
       "[5 rows x 561 columns]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Step 3: because the data is already scaled and split into testing/training sets, I just put the data into Pandas form\n",
    "\n",
    "X_train_df = pd.read_csv(\n",
    "    X_train, delimiter=\" \", skiprows=1, header=None\n",
    ")\n",
    "X_train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "cb14e9b5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.03948004, -0.00213128, -0.02906736, ..., -0.8450924 ,\n",
       "         0.18026111, -0.04743634],\n",
       "       [ 0.03997778, -0.00515272, -0.02265071, ..., -0.84923013,\n",
       "         0.18060956, -0.04227136],\n",
       "       [ 0.03978456, -0.01180878, -0.02891578, ..., -0.84894659,\n",
       "         0.18190709, -0.04082622],\n",
       "       ...,\n",
       "       [ 0.03745094, -0.00272442,  0.02100941, ..., -0.77956634,\n",
       "         0.24912145,  0.04707077],\n",
       "       [ 0.04401105, -0.00453578, -0.0512422 , ..., -0.78560327,\n",
       "         0.24640867,  0.03170003],\n",
       "       [ 0.06895376,  0.00181032, -0.08032343, ..., -0.78369253,\n",
       "         0.24678499,  0.04298129]])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Step 4: I convert the X training values into a numpy array to use Keras\n",
    "X_train = X_train_df.values\n",
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "82ca35b6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>5</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   5\n",
       "0  5\n",
       "1  5\n",
       "2  5\n",
       "3  5\n",
       "4  5"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Step 5: Preprocess the y values (outputs) similar to what I did to the X values\n",
    "\n",
    "y_train_df = pd.read_csv(y_train)\n",
    "y_train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "a38ea42e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0.]],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Step 5a:  One hot encode the labels into a numpy array\n",
    "y_train = to_categorical(y_train_df)\n",
    "y_train[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "ea2dd2e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3161, 561) (3161, 13)\n"
     ]
    }
   ],
   "source": [
    "# Repeat step 3-5 for the testing data\n",
    "\n",
    "X_test_df = pd.read_csv(X_test, delimiter=\" \", skiprows=1, header=None)\n",
    "X_test = X_test_df.values\n",
    "\n",
    "y_test_df = pd.read_csv(y_test)\n",
    "y_test = to_categorical(y_test_df)\n",
    "\n",
    "print(X_test.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fcdc9c49",
   "metadata": {},
   "source": [
    "### Build the Deep Learning Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "2fec189e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 6: Create the model\n",
    "\n",
    "model = Sequential()\n",
    "\n",
    "# The number of input variables (nodes) is equal to the number of categories / columns in the dataset\n",
    "model.add(Dense(units=100, activation=\"relu\", input_dim=X_train.shape[1]))\n",
    "model.add(Dense(units=100, activation='relu'))\n",
    "\n",
    "# The number of output variables (nodes) is equal to the number of possible outputs in the output data (13)\n",
    "model.add(Dense(units=y_train.shape[1], activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "d540f858",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 7: Compile the Model\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "38c46480",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "243/243 - 1s - loss: 0.5560 - accuracy: 0.7929\n",
      "Epoch 2/200\n",
      "243/243 - 0s - loss: 0.2096 - accuracy: 0.9166\n",
      "Epoch 3/200\n",
      "243/243 - 0s - loss: 0.1486 - accuracy: 0.9410\n",
      "Epoch 4/200\n",
      "243/243 - 0s - loss: 0.1283 - accuracy: 0.9500\n",
      "Epoch 5/200\n",
      "243/243 - 0s - loss: 0.1019 - accuracy: 0.9579\n",
      "Epoch 6/200\n",
      "243/243 - 0s - loss: 0.1015 - accuracy: 0.9601\n",
      "Epoch 7/200\n",
      "243/243 - 0s - loss: 0.0871 - accuracy: 0.9650\n",
      "Epoch 8/200\n",
      "243/243 - 0s - loss: 0.0861 - accuracy: 0.9659\n",
      "Epoch 9/200\n",
      "243/243 - 0s - loss: 0.0786 - accuracy: 0.9700\n",
      "Epoch 10/200\n",
      "243/243 - 0s - loss: 0.0708 - accuracy: 0.9722\n",
      "Epoch 11/200\n",
      "243/243 - 0s - loss: 0.0761 - accuracy: 0.9715\n",
      "Epoch 12/200\n",
      "243/243 - 0s - loss: 0.0821 - accuracy: 0.9686\n",
      "Epoch 13/200\n",
      "243/243 - 0s - loss: 0.0666 - accuracy: 0.9740\n",
      "Epoch 14/200\n",
      "243/243 - 0s - loss: 0.0601 - accuracy: 0.9768\n",
      "Epoch 15/200\n",
      "243/243 - 0s - loss: 0.0568 - accuracy: 0.9788\n",
      "Epoch 16/200\n",
      "243/243 - 0s - loss: 0.0624 - accuracy: 0.9749\n",
      "Epoch 17/200\n",
      "243/243 - 0s - loss: 0.0579 - accuracy: 0.9776\n",
      "Epoch 18/200\n",
      "243/243 - 0s - loss: 0.0535 - accuracy: 0.9804\n",
      "Epoch 19/200\n",
      "243/243 - 0s - loss: 0.0519 - accuracy: 0.9786\n",
      "Epoch 20/200\n",
      "243/243 - 0s - loss: 0.0655 - accuracy: 0.9748\n",
      "Epoch 21/200\n",
      "243/243 - 0s - loss: 0.0474 - accuracy: 0.9822\n",
      "Epoch 22/200\n",
      "243/243 - 0s - loss: 0.0475 - accuracy: 0.9818\n",
      "Epoch 23/200\n",
      "243/243 - 0s - loss: 0.0466 - accuracy: 0.9817\n",
      "Epoch 24/200\n",
      "243/243 - 0s - loss: 0.0522 - accuracy: 0.9794\n",
      "Epoch 25/200\n",
      "243/243 - 0s - loss: 0.0503 - accuracy: 0.9806\n",
      "Epoch 26/200\n",
      "243/243 - 0s - loss: 0.0543 - accuracy: 0.9789\n",
      "Epoch 27/200\n",
      "243/243 - 0s - loss: 0.0480 - accuracy: 0.9812\n",
      "Epoch 28/200\n",
      "243/243 - 0s - loss: 0.0475 - accuracy: 0.9826\n",
      "Epoch 29/200\n",
      "243/243 - 0s - loss: 0.0529 - accuracy: 0.9797\n",
      "Epoch 30/200\n",
      "243/243 - 0s - loss: 0.0370 - accuracy: 0.9856\n",
      "Epoch 31/200\n",
      "243/243 - 0s - loss: 0.0381 - accuracy: 0.9851\n",
      "Epoch 32/200\n",
      "243/243 - 0s - loss: 0.0345 - accuracy: 0.9885\n",
      "Epoch 33/200\n",
      "243/243 - 0s - loss: 0.0498 - accuracy: 0.9826\n",
      "Epoch 34/200\n",
      "243/243 - 0s - loss: 0.0338 - accuracy: 0.9876\n",
      "Epoch 35/200\n",
      "243/243 - 0s - loss: 0.0321 - accuracy: 0.9884\n",
      "Epoch 36/200\n",
      "243/243 - 0s - loss: 0.0375 - accuracy: 0.9853\n",
      "Epoch 37/200\n",
      "243/243 - 0s - loss: 0.0606 - accuracy: 0.9777\n",
      "Epoch 38/200\n",
      "243/243 - 0s - loss: 0.0394 - accuracy: 0.9843\n",
      "Epoch 39/200\n",
      "243/243 - 0s - loss: 0.0259 - accuracy: 0.9901\n",
      "Epoch 40/200\n",
      "243/243 - 0s - loss: 0.0358 - accuracy: 0.9866\n",
      "Epoch 41/200\n",
      "243/243 - 0s - loss: 0.0262 - accuracy: 0.9907\n",
      "Epoch 42/200\n",
      "243/243 - 0s - loss: 0.0240 - accuracy: 0.9897\n",
      "Epoch 43/200\n",
      "243/243 - 0s - loss: 0.0290 - accuracy: 0.9896\n",
      "Epoch 44/200\n",
      "243/243 - 0s - loss: 0.0347 - accuracy: 0.9864\n",
      "Epoch 45/200\n",
      "243/243 - 0s - loss: 0.0250 - accuracy: 0.9906\n",
      "Epoch 46/200\n",
      "243/243 - 0s - loss: 0.0361 - accuracy: 0.9871\n",
      "Epoch 47/200\n",
      "243/243 - 0s - loss: 0.0274 - accuracy: 0.9896\n",
      "Epoch 48/200\n",
      "243/243 - 0s - loss: 0.0236 - accuracy: 0.9910\n",
      "Epoch 49/200\n",
      "243/243 - 0s - loss: 0.0314 - accuracy: 0.9884\n",
      "Epoch 50/200\n",
      "243/243 - 0s - loss: 0.0293 - accuracy: 0.9896\n",
      "Epoch 51/200\n",
      "243/243 - 0s - loss: 0.0340 - accuracy: 0.9875\n",
      "Epoch 52/200\n",
      "243/243 - 0s - loss: 0.0229 - accuracy: 0.9921\n",
      "Epoch 53/200\n",
      "243/243 - 0s - loss: 0.0356 - accuracy: 0.9867\n",
      "Epoch 54/200\n",
      "243/243 - 0s - loss: 0.0222 - accuracy: 0.9919\n",
      "Epoch 55/200\n",
      "243/243 - 0s - loss: 0.0258 - accuracy: 0.9905\n",
      "Epoch 56/200\n",
      "243/243 - 0s - loss: 0.0217 - accuracy: 0.9923\n",
      "Epoch 57/200\n",
      "243/243 - 0s - loss: 0.0164 - accuracy: 0.9932\n",
      "Epoch 58/200\n",
      "243/243 - 0s - loss: 0.0321 - accuracy: 0.9883\n",
      "Epoch 59/200\n",
      "243/243 - 0s - loss: 0.0374 - accuracy: 0.9867\n",
      "Epoch 60/200\n",
      "243/243 - 0s - loss: 0.0178 - accuracy: 0.9916\n",
      "Epoch 61/200\n",
      "243/243 - 0s - loss: 0.0180 - accuracy: 0.9930\n",
      "Epoch 62/200\n",
      "243/243 - 0s - loss: 0.0152 - accuracy: 0.9950\n",
      "Epoch 63/200\n",
      "243/243 - 0s - loss: 0.0186 - accuracy: 0.9929\n",
      "Epoch 64/200\n",
      "243/243 - 0s - loss: 0.0123 - accuracy: 0.9958\n",
      "Epoch 65/200\n",
      "243/243 - 0s - loss: 0.0167 - accuracy: 0.9938\n",
      "Epoch 66/200\n",
      "243/243 - 0s - loss: 0.0177 - accuracy: 0.9928\n",
      "Epoch 67/200\n",
      "243/243 - 0s - loss: 0.0116 - accuracy: 0.9956\n",
      "Epoch 68/200\n",
      "243/243 - 0s - loss: 0.0331 - accuracy: 0.9893\n",
      "Epoch 69/200\n",
      "243/243 - 0s - loss: 0.0234 - accuracy: 0.9911\n",
      "Epoch 70/200\n",
      "243/243 - 0s - loss: 0.0122 - accuracy: 0.9956\n",
      "Epoch 71/200\n",
      "243/243 - 0s - loss: 0.0184 - accuracy: 0.9937\n",
      "Epoch 72/200\n",
      "243/243 - 0s - loss: 0.0522 - accuracy: 0.9839\n",
      "Epoch 73/200\n",
      "243/243 - 0s - loss: 0.0156 - accuracy: 0.9937\n",
      "Epoch 74/200\n",
      "243/243 - 0s - loss: 0.0157 - accuracy: 0.9939\n",
      "Epoch 75/200\n",
      "243/243 - 0s - loss: 0.0115 - accuracy: 0.9955\n",
      "Epoch 76/200\n",
      "243/243 - 0s - loss: 0.0282 - accuracy: 0.9907\n",
      "Epoch 77/200\n",
      "243/243 - 0s - loss: 0.0120 - accuracy: 0.9948\n",
      "Epoch 78/200\n",
      "243/243 - 0s - loss: 0.0069 - accuracy: 0.9977\n",
      "Epoch 79/200\n",
      "243/243 - 0s - loss: 0.0106 - accuracy: 0.9965\n",
      "Epoch 80/200\n",
      "243/243 - 0s - loss: 0.0403 - accuracy: 0.9860\n",
      "Epoch 81/200\n",
      "243/243 - 0s - loss: 0.0157 - accuracy: 0.9938\n",
      "Epoch 82/200\n",
      "243/243 - 0s - loss: 0.0216 - accuracy: 0.9927\n",
      "Epoch 83/200\n",
      "243/243 - 0s - loss: 0.0205 - accuracy: 0.9936\n",
      "Epoch 84/200\n",
      "243/243 - 0s - loss: 0.0260 - accuracy: 0.9901\n",
      "Epoch 85/200\n",
      "243/243 - 0s - loss: 0.0105 - accuracy: 0.9959\n",
      "Epoch 86/200\n",
      "243/243 - 0s - loss: 0.0036 - accuracy: 0.9988\n",
      "Epoch 87/200\n",
      "243/243 - 0s - loss: 0.0108 - accuracy: 0.9959\n",
      "Epoch 88/200\n",
      "243/243 - 0s - loss: 0.0060 - accuracy: 0.9976\n",
      "Epoch 89/200\n",
      "243/243 - 0s - loss: 0.0125 - accuracy: 0.9960\n",
      "Epoch 90/200\n",
      "243/243 - 0s - loss: 0.0170 - accuracy: 0.9959\n",
      "Epoch 91/200\n",
      "243/243 - 0s - loss: 0.0250 - accuracy: 0.9916\n",
      "Epoch 92/200\n",
      "243/243 - 0s - loss: 0.0172 - accuracy: 0.9952\n",
      "Epoch 93/200\n",
      "243/243 - 0s - loss: 0.0052 - accuracy: 0.9983\n",
      "Epoch 94/200\n",
      "243/243 - 0s - loss: 0.0194 - accuracy: 0.9945\n",
      "Epoch 95/200\n",
      "243/243 - 0s - loss: 0.0187 - accuracy: 0.9932\n",
      "Epoch 96/200\n",
      "243/243 - 0s - loss: 0.0213 - accuracy: 0.9934\n",
      "Epoch 97/200\n",
      "243/243 - 0s - loss: 0.0121 - accuracy: 0.9955\n",
      "Epoch 98/200\n",
      "243/243 - 0s - loss: 0.0036 - accuracy: 0.9988\n",
      "Epoch 99/200\n",
      "243/243 - 0s - loss: 0.0084 - accuracy: 0.9961\n",
      "Epoch 100/200\n",
      "243/243 - 0s - loss: 0.0183 - accuracy: 0.9928\n",
      "Epoch 101/200\n",
      "243/243 - 0s - loss: 0.0219 - accuracy: 0.9912\n",
      "Epoch 102/200\n",
      "243/243 - 0s - loss: 0.0060 - accuracy: 0.9983\n",
      "Epoch 103/200\n",
      "243/243 - 0s - loss: 0.0147 - accuracy: 0.9948\n",
      "Epoch 104/200\n",
      "243/243 - 0s - loss: 0.0118 - accuracy: 0.9960\n",
      "Epoch 105/200\n",
      "243/243 - 0s - loss: 0.0075 - accuracy: 0.9968\n",
      "Epoch 106/200\n",
      "243/243 - 0s - loss: 0.0064 - accuracy: 0.9978\n",
      "Epoch 107/200\n",
      "243/243 - 0s - loss: 0.0015 - accuracy: 0.9997\n",
      "Epoch 108/200\n",
      "243/243 - 0s - loss: 0.0041 - accuracy: 0.9991\n",
      "Epoch 109/200\n",
      "243/243 - 0s - loss: 0.0244 - accuracy: 0.9918\n",
      "Epoch 110/200\n",
      "243/243 - 0s - loss: 0.0427 - accuracy: 0.9888\n",
      "Epoch 111/200\n",
      "243/243 - 0s - loss: 0.0184 - accuracy: 0.9938\n",
      "Epoch 112/200\n",
      "243/243 - 0s - loss: 0.0055 - accuracy: 0.9979\n",
      "Epoch 113/200\n",
      "243/243 - 0s - loss: 0.0141 - accuracy: 0.9945\n",
      "Epoch 114/200\n",
      "243/243 - 0s - loss: 0.0040 - accuracy: 0.9991\n",
      "Epoch 115/200\n",
      "243/243 - 0s - loss: 0.0087 - accuracy: 0.9963\n",
      "Epoch 116/200\n",
      "243/243 - 0s - loss: 0.0104 - accuracy: 0.9963\n",
      "Epoch 117/200\n",
      "243/243 - 0s - loss: 0.0067 - accuracy: 0.9974\n",
      "Epoch 118/200\n",
      "243/243 - 0s - loss: 0.0023 - accuracy: 0.9994\n",
      "Epoch 119/200\n",
      "243/243 - 0s - loss: 0.0153 - accuracy: 0.9951\n",
      "Epoch 120/200\n",
      "243/243 - 0s - loss: 0.0307 - accuracy: 0.9906\n",
      "Epoch 121/200\n",
      "243/243 - 0s - loss: 0.0079 - accuracy: 0.9976\n",
      "Epoch 122/200\n",
      "243/243 - 0s - loss: 0.0145 - accuracy: 0.9946\n",
      "Epoch 123/200\n",
      "243/243 - 0s - loss: 0.0038 - accuracy: 0.9992\n",
      "Epoch 124/200\n",
      "243/243 - 0s - loss: 0.0042 - accuracy: 0.9987\n",
      "Epoch 125/200\n",
      "243/243 - 0s - loss: 0.0150 - accuracy: 0.9943\n",
      "Epoch 126/200\n",
      "243/243 - 0s - loss: 0.0115 - accuracy: 0.9965\n",
      "Epoch 127/200\n",
      "243/243 - 0s - loss: 0.0281 - accuracy: 0.9927\n",
      "Epoch 128/200\n",
      "243/243 - 0s - loss: 0.0084 - accuracy: 0.9976\n",
      "Epoch 129/200\n",
      "243/243 - 0s - loss: 0.0019 - accuracy: 0.9994\n",
      "Epoch 130/200\n",
      "243/243 - 0s - loss: 7.0526e-04 - accuracy: 1.0000\n",
      "Epoch 131/200\n",
      "243/243 - 0s - loss: 0.0247 - accuracy: 0.9936\n",
      "Epoch 132/200\n",
      "243/243 - 0s - loss: 0.0174 - accuracy: 0.9956\n",
      "Epoch 133/200\n",
      "243/243 - 0s - loss: 0.0041 - accuracy: 0.9986\n",
      "Epoch 134/200\n",
      "243/243 - 0s - loss: 0.0042 - accuracy: 0.9988\n",
      "Epoch 135/200\n",
      "243/243 - 0s - loss: 0.0123 - accuracy: 0.9965\n",
      "Epoch 136/200\n",
      "243/243 - 0s - loss: 0.0055 - accuracy: 0.9981\n",
      "Epoch 137/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "243/243 - 0s - loss: 0.0043 - accuracy: 0.9983\n",
      "Epoch 138/200\n",
      "243/243 - 0s - loss: 5.9327e-04 - accuracy: 1.0000\n",
      "Epoch 139/200\n",
      "243/243 - 0s - loss: 0.0394 - accuracy: 0.9867\n",
      "Epoch 140/200\n",
      "243/243 - 0s - loss: 0.0146 - accuracy: 0.9955\n",
      "Epoch 141/200\n",
      "243/243 - 0s - loss: 0.0027 - accuracy: 0.9994\n",
      "Epoch 142/200\n",
      "243/243 - 0s - loss: 4.7086e-04 - accuracy: 1.0000\n",
      "Epoch 143/200\n",
      "243/243 - 0s - loss: 3.9759e-04 - accuracy: 1.0000\n",
      "Epoch 144/200\n",
      "243/243 - 0s - loss: 5.3870e-04 - accuracy: 1.0000\n",
      "Epoch 145/200\n",
      "243/243 - 0s - loss: 2.9191e-04 - accuracy: 1.0000\n",
      "Epoch 146/200\n",
      "243/243 - 0s - loss: 0.0011 - accuracy: 0.9997\n",
      "Epoch 147/200\n",
      "243/243 - 0s - loss: 2.6732e-04 - accuracy: 1.0000\n",
      "Epoch 148/200\n",
      "243/243 - 0s - loss: 2.0220e-04 - accuracy: 1.0000\n",
      "Epoch 149/200\n",
      "243/243 - 0s - loss: 0.0493 - accuracy: 0.9871\n",
      "Epoch 150/200\n",
      "243/243 - 0s - loss: 0.0058 - accuracy: 0.9983\n",
      "Epoch 151/200\n",
      "243/243 - 0s - loss: 0.0012 - accuracy: 0.9997\n",
      "Epoch 152/200\n",
      "243/243 - 0s - loss: 0.0024 - accuracy: 0.9994\n",
      "Epoch 153/200\n",
      "243/243 - 0s - loss: 3.4481e-04 - accuracy: 1.0000\n",
      "Epoch 154/200\n",
      "243/243 - 0s - loss: 4.2484e-04 - accuracy: 1.0000\n",
      "Epoch 155/200\n",
      "243/243 - 0s - loss: 1.9886e-04 - accuracy: 1.0000\n",
      "Epoch 156/200\n",
      "243/243 - 0s - loss: 1.5579e-04 - accuracy: 1.0000\n",
      "Epoch 157/200\n",
      "243/243 - 0s - loss: 1.5887e-04 - accuracy: 1.0000\n",
      "Epoch 158/200\n",
      "243/243 - 0s - loss: 1.0654e-04 - accuracy: 1.0000\n",
      "Epoch 159/200\n",
      "243/243 - 0s - loss: 9.7429e-05 - accuracy: 1.0000\n",
      "Epoch 160/200\n",
      "243/243 - 0s - loss: 9.1841e-05 - accuracy: 1.0000\n",
      "Epoch 161/200\n",
      "243/243 - 0s - loss: 7.7787e-05 - accuracy: 1.0000\n",
      "Epoch 162/200\n",
      "243/243 - 0s - loss: 6.8711e-05 - accuracy: 1.0000\n",
      "Epoch 163/200\n",
      "243/243 - 0s - loss: 7.3646e-05 - accuracy: 1.0000\n",
      "Epoch 164/200\n",
      "243/243 - 0s - loss: 3.5356e-04 - accuracy: 0.9997\n",
      "Epoch 165/200\n",
      "243/243 - 0s - loss: 0.0836 - accuracy: 0.9777\n",
      "Epoch 166/200\n",
      "243/243 - 0s - loss: 0.0079 - accuracy: 0.9972\n",
      "Epoch 167/200\n",
      "243/243 - 0s - loss: 0.0039 - accuracy: 0.9991\n",
      "Epoch 168/200\n",
      "243/243 - 0s - loss: 0.0079 - accuracy: 0.9970\n",
      "Epoch 169/200\n",
      "243/243 - 0s - loss: 0.0177 - accuracy: 0.9941\n",
      "Epoch 170/200\n",
      "243/243 - 0s - loss: 0.0052 - accuracy: 0.9983\n",
      "Epoch 171/200\n",
      "243/243 - 0s - loss: 0.0021 - accuracy: 0.9997\n",
      "Epoch 172/200\n",
      "243/243 - 0s - loss: 0.0149 - accuracy: 0.9952\n",
      "Epoch 173/200\n",
      "243/243 - 0s - loss: 0.0039 - accuracy: 0.9987\n",
      "Epoch 174/200\n",
      "243/243 - 0s - loss: 0.0142 - accuracy: 0.9955\n",
      "Epoch 175/200\n",
      "243/243 - 0s - loss: 0.0072 - accuracy: 0.9973\n",
      "Epoch 176/200\n",
      "243/243 - 0s - loss: 0.0023 - accuracy: 0.9996\n",
      "Epoch 177/200\n",
      "243/243 - 0s - loss: 0.0068 - accuracy: 0.9965\n",
      "Epoch 178/200\n",
      "243/243 - 0s - loss: 0.0198 - accuracy: 0.9936\n",
      "Epoch 179/200\n",
      "243/243 - 0s - loss: 0.0152 - accuracy: 0.9948\n",
      "Epoch 180/200\n",
      "243/243 - 0s - loss: 0.0051 - accuracy: 0.9978\n",
      "Epoch 181/200\n",
      "243/243 - 0s - loss: 0.0014 - accuracy: 0.9996\n",
      "Epoch 182/200\n",
      "243/243 - 0s - loss: 0.0034 - accuracy: 0.9988\n",
      "Epoch 183/200\n",
      "243/243 - 0s - loss: 0.0012 - accuracy: 0.9997\n",
      "Epoch 184/200\n",
      "243/243 - 0s - loss: 0.0156 - accuracy: 0.9956\n",
      "Epoch 185/200\n",
      "243/243 - 0s - loss: 0.0215 - accuracy: 0.9946\n",
      "Epoch 186/200\n",
      "243/243 - 0s - loss: 0.0029 - accuracy: 0.9990\n",
      "Epoch 187/200\n",
      "243/243 - 0s - loss: 4.6468e-04 - accuracy: 1.0000\n",
      "Epoch 188/200\n",
      "243/243 - 0s - loss: 2.8870e-04 - accuracy: 1.0000\n",
      "Epoch 189/200\n",
      "243/243 - 0s - loss: 0.0226 - accuracy: 0.9938\n",
      "Epoch 190/200\n",
      "243/243 - 0s - loss: 0.0067 - accuracy: 0.9977\n",
      "Epoch 191/200\n",
      "243/243 - 0s - loss: 0.0035 - accuracy: 0.9987\n",
      "Epoch 192/200\n",
      "243/243 - 0s - loss: 0.0026 - accuracy: 0.9994\n",
      "Epoch 193/200\n",
      "243/243 - 0s - loss: 0.0120 - accuracy: 0.9958\n",
      "Epoch 194/200\n",
      "243/243 - 0s - loss: 0.0282 - accuracy: 0.9910\n",
      "Epoch 195/200\n",
      "243/243 - 0s - loss: 0.0074 - accuracy: 0.9977\n",
      "Epoch 196/200\n",
      "243/243 - 0s - loss: 0.0026 - accuracy: 0.9995\n",
      "Epoch 197/200\n",
      "243/243 - 0s - loss: 0.0021 - accuracy: 0.9994\n",
      "Epoch 198/200\n",
      "243/243 - 0s - loss: 9.9183e-04 - accuracy: 0.9999\n",
      "Epoch 199/200\n",
      "243/243 - 0s - loss: 0.0074 - accuracy: 0.9979\n",
      "Epoch 200/200\n",
      "243/243 - 0s - loss: 0.0216 - accuracy: 0.9937\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x20a855e3fa0>"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Step 8: Train (fit) the data to the training datasets\n",
    "model.fit(\n",
    "    X_train,\n",
    "    y_train,\n",
    "    epochs=200,\n",
    "    shuffle=True,\n",
    "    verbose=2\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffe4dd8a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
