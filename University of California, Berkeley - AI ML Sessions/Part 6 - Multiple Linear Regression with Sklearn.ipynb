{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dependencies\n",
    "\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Multi-Linear Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Multiple Linear Regression just means that you have multiple features (X) to consider\n",
    "\n",
    "For Example:  \n",
    "\n",
    "Y = Bias + X*Feature1 + X*Feature2 + X*Feature3 ...\n",
    "\n",
    "More commonly written as:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"images/multilinear regression formula.png\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(30, 3)\n",
      "(30,)\n",
      "[[ 1.56464366 -2.6197451  -0.03582604]\n",
      " [-1.4123037   1.46564877 -0.90802408]\n",
      " [ 1.47789404 -0.51827022  0.35711257]\n",
      " [-0.3011037  -1.47852199 -0.11564828]\n",
      " [ 0.73846658  0.17136828  0.19686124]\n",
      " [ 0.0675282  -1.42474819 -0.2257763 ]\n",
      " [-0.18565898 -1.10633497 -0.47917424]\n",
      " [-1.95967012 -1.32818605  0.2088636 ]\n",
      " [-0.60063869 -0.29169375  0.37569802]\n",
      " [-0.50175704  0.91540212 -0.8084936 ]\n",
      " [ 0.76743473 -0.46947439  1.57921282]\n",
      " [ 0.81252582  1.35624003 -1.19620662]\n",
      " [ 0.93128012 -0.83921752  1.03099952]\n",
      " [ 0.82254491 -1.22084365 -1.05771093]\n",
      " [ 0.11092259 -1.15099358 -0.54438272]\n",
      " [-0.1382643   0.64768854  0.49671415]\n",
      " [-0.676922    0.61167629 -0.38508228]\n",
      " [-0.46063877  1.05712223 -0.71984421]\n",
      " [-1.98756891 -0.21967189  0.09176078]\n",
      " [ 0.08704707 -0.29900735  0.8219025 ]\n",
      " [-0.23415337 -0.23413696  1.52302986]\n",
      " [ 0.33126343  0.97554513 -0.30921238]\n",
      " [-1.91328024 -1.72491783  0.24196227]\n",
      " [-1.01283112  0.31424733 -0.56228753]\n",
      " [-1.76304016  0.32408397  0.34361829]\n",
      " [ 0.36139561  1.53803657 -0.64511975]\n",
      " [ 1.85227818 -0.01349722 -0.60170661]\n",
      " [-0.5297602   0.51326743  0.32875111]\n",
      " [-0.46341769 -0.46572975  0.54256004]\n",
      " [ 1.0035329   0.36163603 -0.07201012]]\n",
      "[ -30.09970593   59.79676852  169.525505    -46.41541667  170.22545453\n",
      "  -31.37691622  -42.06125512  -94.18658521   77.44118985   74.85845235\n",
      "  244.30949544  146.3464125   173.95260222  -48.70246812  -35.74044762\n",
      "  189.01981997   77.67231907   96.96373549  -17.03234168  153.78189524\n",
      "  204.74192439  168.54054512 -120.2346508    20.41387506   61.74032229\n",
      "  186.10006444  145.33196979  142.21035403   85.64380786  176.56779377]\n"
     ]
    }
   ],
   "source": [
    "# The only difference is that now you have multiple X's (features) to train\n",
    "\n",
    "from sklearn.datasets import make_regression\n",
    "\n",
    "n_features = 3\n",
    "X, y = make_regression(n_samples=30, n_features=n_features, n_informative=n_features, \n",
    "                      random_state=42, noise=0.5, bias=100.0)\n",
    "\n",
    "#NOTE: n_informative is saying that all features (3) have an impact on the output.\n",
    "\n",
    "print(X.shape)\n",
    "print(y.shape)\n",
    "print(X)\n",
    "print(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Plotting a 3 dimensional plot using 3 features is hard for a human to comprehend. Things get more complicated as we code it out, but luckily we can just supply our n_dimensional features and sklearn will fit the model using all of our features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Linear Regression dependencies\n",
    "from sklearn.linear_model import LinearRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LinearRegression()"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Step 1: Fit (train) the model for all features (X)\n",
    "model = LinearRegression()\n",
    "model.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R Squared Score: 0.9999838079561164\n"
     ]
    }
   ],
   "source": [
    "score = model.score(X, y)\n",
    "print(\"R Squared Score: {}\".format(score))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Residuals\n",
    "\n",
    "Because we cannot easily plot our line in a 3D space, we can use a residual plot to check our predictions.  \n",
    "\n",
    "Residuals are the difference between the true values of y (from dataset) and the predicted values (model.predict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 2: predict the model\n",
    "predictions = model.predict(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Step 3: Plot the residuals\n",
    "plt.scatter(predictions, predictions - y)\n",
    "plt.hlines(y=0, xmin=predictions.min(), xmax=predictions.max())\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Goal: We want our predictions to be close to zero on the y_axis as possible"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### How to read a Residual plot (above)\n",
    "\n",
    "1) First notice the blue dots. Blue dots = your predicted y (outout)\n",
    "- you can generalize that the points are pretty scattered, but still most are somewhat near the line at y=0.  \n",
    "\n",
    "2) Each blue dot corresponds to a point on the x-axis. The number it corresponds to on the x-axis is the predicted-y's value.  \n",
    "\n",
    "3) Each blue dot also corresponds to a y-axis value. The number it corresponds to on the y_axis is how far the predicted-y was from the true-y.\n",
    "\n",
    "Rule of thumb: when using residual plots to 'read' multi-linear regressions, the closer the dots are to the line at y=0, the more accurate the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
