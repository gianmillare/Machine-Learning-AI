{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2acd18f2",
   "metadata": {},
   "source": [
    "# MNIST"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90dfc637",
   "metadata": {},
   "source": [
    "\"The MNIST database (Modified National Institute of Standards and Technology database) is a large database of handwritten digits that is commonly used for training various image processing systems. The database is also widely used for training and testing in the field of machine learning.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "0c0140eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1: Import the Dependencies\n",
    "\n",
    "# Usual dependencies\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import numpy as np\n",
    "\n",
    "# new dependencies\n",
    "from IPython.display import Image, SVG\n",
    "import tensorflow as tf\n",
    "from sklearn.preprocessing import MinMaxScaler #this scales the data based on the minimum and maximum values\n",
    "\n",
    "# keras specific dependencies\n",
    "from keras.models import Sequential\n",
    "from keras.utils import to_categorical\n",
    "from keras.layers import Dense\n",
    "from keras.datasets import mnist"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5caa9b89",
   "metadata": {},
   "source": [
    "### Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "12db2200",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data Features Shape: (60000, 28, 28)\n",
      "--------------------\n",
      "Data Labels Shape: (60000,)\n"
     ]
    }
   ],
   "source": [
    "# Step 2: load in the MNIST data using the cariable format (X_train, y_train), (X_test, y_test)\n",
    "(X_train, y_train), (X_test, y_test) = mnist.load_data()\n",
    "print(f\"Data Features Shape: {X_train.shape}\")\n",
    "print(\"-----\" * 4)\n",
    "print(f\"Data Labels Shape: {y_train.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "09b7ec89",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Note: the features is a 3dimensional array and the labels are 1dimensional"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "313ebca2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x26488831490>"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Step 3: Plot the data to see what it looks like\n",
    "\n",
    "plt.imshow(X_train[0, :, :], cmap=plt.cm.Greys)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "273cfb7a",
   "metadata": {},
   "source": [
    "Each image is a 28x28 pixel greyscale image with values 0-255 (color scale)  \n",
    "\n",
    "That is usually what an image is. It is an array of pixels ranging from 0-255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "8e8601d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   3  18  18  18 126 136\n",
      "  175  26 166 255 247 127   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0  30  36  94 154 170 253 253 253 253 253\n",
      "  225 172 253 242 195  64   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0  49 238 253 253 253 253 253 253 253 253 251\n",
      "   93  82  82  56  39   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0  18 219 253 253 253 253 253 198 182 247 241\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0  80 156 107 253 253 205  11   0  43 154\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0  14   1 154 253  90   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0 139 253 190   2   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0  11 190 253  70   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0  35 241 225 160 108   1\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0  81 240 253 253 119\n",
      "   25   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0  45 186 253 253\n",
      "  150  27   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0  16  93 252\n",
      "  253 187   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0 249\n",
      "  253 249  64   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0  46 130 183 253\n",
      "  253 207   2   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0  39 148 229 253 253 253\n",
      "  250 182   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0  24 114 221 253 253 253 253 201\n",
      "   78   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0  23  66 213 253 253 253 253 198  81   2\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0  18 171 219 253 253 253 253 195  80   9   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0  55 172 226 253 253 253 253 244 133  11   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0 136 253 253 253 212 135 132  16   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0]]\n"
     ]
    }
   ],
   "source": [
    "print(X_train[0,:,:])\n",
    "\n",
    "# view the below and you can sort of see the image structure using the numbers"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c904d7ee",
   "metadata": {},
   "source": [
    "### I need to flatten the data into rows of 1d image arrays in order to make a neural network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "87e87cc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 4: To \"flatten\" the data,we multiply the second and third dimensions (28 * 28)\n",
    "ndims = X_train.shape[1] * X_train.shape[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "2e1f040d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 5: Then I reshape the datasets to match a 2dimensional numpy array (60000, 784)\n",
    "X_train = X_train.reshape(X_train.shape[0], ndims)\n",
    "X_test = X_test.reshape(X_test.shape[0], ndims)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "9318e0b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Data: (60000, 784)\n",
      "Testing Data: (10000, 784)\n"
     ]
    }
   ],
   "source": [
    "print(f\"Training Data: {X_train.shape}\")\n",
    "print(f\"Testing Data: {X_test.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d06107d6",
   "metadata": {},
   "source": [
    "### I scale and normalize the dataset to 0-1. This makes the weights a little more \"balanced\" than if it were 0-255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "e2427304",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 6: Scale and Normalize the datasets using MinMaxScaler\n",
    "scaler = MinMaxScaler().fit(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "8a04aa1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 7: Transform the X_train and the X_test to the trained and scaled dataset\n",
    "X_train = scaler.transform(X_train)\n",
    "X_test = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4bb037c6",
   "metadata": {},
   "source": [
    "### This concludes the preprocessing of the features"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd6ce187",
   "metadata": {},
   "source": [
    "### Next step is to preprocess the labels (outputs)\n",
    "\n",
    "IMPORTANT: The reason we need one hot encoding is because the output is expected to be of categorical value as opposed to a regressional value. The current output data we have are all integers (which is obviously not a categorical output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "700a286b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([5, 0, 4, 1, 9, 2, 1, 3, 1, 4, 3, 5, 3, 6, 1, 7, 2, 8, 6, 9],\n",
       "      dtype=uint8)"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Step 8: One hot encoding to change our integers labels to categorical values\n",
    "y_train[:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "68ed9f05",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 0., 0., 0., 0., 1., 0., 0., 0., 0.], dtype=float32)"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# We can assume that each \"label\" is a number between 0-9 as shown above. \n",
    "# Because we know the \"limit\" is between 0-9, we can set a class limit when applying to_categorical to the output data\n",
    "lim_classes = 10\n",
    "y_train = to_categorical(y_train, lim_classes)\n",
    "y_test = to_categorical(y_test, lim_classes)\n",
    "\n",
    "# view the first \"output that was shown above\"\n",
    "y_train[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f0b000d",
   "metadata": {},
   "source": [
    "### The '5' from before the one hot encoding is now encoded as [0,0,0,0,0,1,0,0,0,0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af29469b",
   "metadata": {},
   "source": [
    "# Building a Deep Multi-Layer Perceptron Model\n",
    "\n",
    "... with 2 hidden layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "cfbeaddf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 9: Create a Sequential Model\n",
    "\n",
    "model = Sequential()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "6d39fdcc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 10: Create the first hidden layer. For this, I will specify the dimensions of the input layer.\n",
    "# The input layer dimensions is just the number of total pixels (28 x 28, or 784)\n",
    "model.add(Dense(units=100, activation='relu', input_dim=X_train.shape[1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71707683",
   "metadata": {},
   "source": [
    "### What is a Deep Multi-Layer Perceptron Model\n",
    "\n",
    "When we connect all nodes from the first hidden layer to the next hidden layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "1c01bdb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 11: Create another hidden layer\n",
    "model.add(Dense(units=100, activation='relu'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "40b987e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 12: Create the output layer using softmax activation for logistic regression.\n",
    "# Just like the input layer, we specify the number of classes in the output layer (10 because one hot encoded for 0-9)\n",
    "model.add(Dense(lim_classes, activation='softmax'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9c9a3b8",
   "metadata": {},
   "source": [
    "# Compiling the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "8b1bf7be",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 13: compile the model with adam optimizer, categorical crossentropy, and accuracy as a metric\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "3f39adcd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense (Dense)                (None, 100)               78500     \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 10)                1010      \n",
      "=================================================================\n",
      "Total params: 89,610\n",
      "Trainable params: 89,610\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Step 14: Summarize the model (for records)\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a61e944",
   "metadata": {},
   "source": [
    "# Train the Deep Multi-Layer Perceptron Model\n",
    "\n",
    "Recap: training is when we update our weights using an optimizer (adam) and a loss function (categorical crossentropy) across a number of iterations (or epochs). Shuffling is optional but is used commonly to increase detail of each cycle."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "47479f60",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/25\n",
      "1875/1875 - 1s - loss: 0.2476 - accuracy: 0.9270\n",
      "Epoch 2/25\n",
      "1875/1875 - 1s - loss: 0.1057 - accuracy: 0.9674\n",
      "Epoch 3/25\n",
      "1875/1875 - 1s - loss: 0.0755 - accuracy: 0.9762\n",
      "Epoch 4/25\n",
      "1875/1875 - 1s - loss: 0.0568 - accuracy: 0.9817\n",
      "Epoch 5/25\n",
      "1875/1875 - 1s - loss: 0.0473 - accuracy: 0.9846\n",
      "Epoch 6/25\n",
      "1875/1875 - 1s - loss: 0.0384 - accuracy: 0.9879\n",
      "Epoch 7/25\n",
      "1875/1875 - 1s - loss: 0.0330 - accuracy: 0.9890\n",
      "Epoch 8/25\n",
      "1875/1875 - 1s - loss: 0.0266 - accuracy: 0.9908\n",
      "Epoch 9/25\n",
      "1875/1875 - 1s - loss: 0.0243 - accuracy: 0.9921\n",
      "Epoch 10/25\n",
      "1875/1875 - 1s - loss: 0.0209 - accuracy: 0.9928\n",
      "Epoch 11/25\n",
      "1875/1875 - 1s - loss: 0.0172 - accuracy: 0.9940\n",
      "Epoch 12/25\n",
      "1875/1875 - 1s - loss: 0.0189 - accuracy: 0.9934\n",
      "Epoch 13/25\n",
      "1875/1875 - 1s - loss: 0.0151 - accuracy: 0.9950\n",
      "Epoch 14/25\n",
      "1875/1875 - 1s - loss: 0.0158 - accuracy: 0.9946\n",
      "Epoch 15/25\n",
      "1875/1875 - 1s - loss: 0.0132 - accuracy: 0.9957\n",
      "Epoch 16/25\n",
      "1875/1875 - 1s - loss: 0.0124 - accuracy: 0.9959\n",
      "Epoch 17/25\n",
      "1875/1875 - 1s - loss: 0.0127 - accuracy: 0.9957\n",
      "Epoch 18/25\n",
      "1875/1875 - 1s - loss: 0.0121 - accuracy: 0.9961\n",
      "Epoch 19/25\n",
      "1875/1875 - 1s - loss: 0.0134 - accuracy: 0.9959\n",
      "Epoch 20/25\n",
      "1875/1875 - 1s - loss: 0.0096 - accuracy: 0.9968\n",
      "Epoch 21/25\n",
      "1875/1875 - 1s - loss: 0.0098 - accuracy: 0.9968\n",
      "Epoch 22/25\n",
      "1875/1875 - 1s - loss: 0.0114 - accuracy: 0.9963\n",
      "Epoch 23/25\n",
      "1875/1875 - 1s - loss: 0.0099 - accuracy: 0.9971\n",
      "Epoch 24/25\n",
      "1875/1875 - 1s - loss: 0.0073 - accuracy: 0.9978\n",
      "Epoch 25/25\n",
      "1875/1875 - 1s - loss: 0.0107 - accuracy: 0.9969\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x2648b70b130>"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Step 15: Train the compiled model\n",
    "\n",
    "model.fit(X_train, y_train, epochs=25, shuffle=True,verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "520b80fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optional Step: Saving and loading the model\n",
    "model.save(\"models/mnist_model.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "b9f3aacd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import load_model\n",
    "model = load_model(\"models/mnist_model.h5\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8e04f7f",
   "metadata": {},
   "source": [
    "# Evaluating the Deep Multi-Layer Perceptron Model\n",
    "\n",
    "Using the testing data on the trained model to validate the strength/accuracy of the model. (testing the ability to predict new and previously seen data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "3b97ae91",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 - 0s - loss: 0.1555 - accuracy: 0.9756\n"
     ]
    }
   ],
   "source": [
    "# Step 16: create the mode_loss and model_accuracy from model.evaluate\n",
    "model_loss, model_accuracy = model.evaluate(\n",
    "    X_test, y_test, verbose=2\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1204d969",
   "metadata": {},
   "source": [
    "# Make Predictions\n",
    "\n",
    "Now that the accuracy is at a good point (98%), we make predictions by inputting new data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3249e058",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
