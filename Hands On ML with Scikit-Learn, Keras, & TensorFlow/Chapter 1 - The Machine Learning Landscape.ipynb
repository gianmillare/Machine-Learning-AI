{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ch. 1 - The Machine Learning Landscape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Type of Machine Learning Systems"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### <strong>Supervised  Learning<strone>\n",
    "\n",
    "<u>Definition</u>: The training set (data) you feed into the algorithm includes the desired solution (often called 'labels').\n",
    "\n",
    "Example: Classification is a typical supervised learning task. Spam filters is an example of Supervised Learning, where users tell the filter what is Spam / Ham and the machine learns to classify future emails as Spam as a result. \n",
    "\n",
    "Example: Predictions is another use case for supervised learning. We can predict numerical values (i.e. prices) given a set of features (brands, mileage, etc.) called predictors. \n",
    "\n",
    "This is a <strong>Regression</strong> based approach to Supervised Learning. To train the model, you would need to give the computer examples. For example: Honda average car is 30,000 and Mercedes average car is 70,000.\n",
    "\n",
    "<strong>Logistic Regression</strong> is another type of regression that is often used in classifications. Logistic regression can be used to find the probability rhat something belongs to a specific class (i.e. this email has a 20% chance of being spam)\n",
    "\n",
    "<u>Examples of Supervised Learning Algorithms</u>  \n",
    "k-Nearest Neighbors  \n",
    "Linear Regression  \n",
    "Logistic Regression  \n",
    "Support Vector Machines (SVMs)  \n",
    "Decision Trees & Random Forests  \n",
    "Neural Networks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### <strong>Unsupervised Learning</strong>\n",
    "<u>Definition</u>: When feeding data into the system, the training data is unlabeled. In other words, the system tries to learn without a teacher.\n",
    "\n",
    "<u>Examples of Unsupervised Learning Algorithms</u>  \n",
    "Clustering: K-Means, DBSCAN, Hierarchical Cluster Analysis (HCA)  \n",
    "Anomaly Detection and Novelty Detection: One-class SVM, Isolation Forest  \n",
    "Visualization and Dimensionality Reduction: Kernel PCA, Locally Linear Embedding (LLE)  \n",
    "Association Rule Learning: Apriori, Eclat\n",
    "\n",
    "<u>Examples</u>  \n",
    "You own a website/blog and want to know if your visitors have any similarities. In this case, you do not tell the system what the categories/classifications are. Instead the system does it for you. For example, if most of your viewers are Males and visit in the evening, the system may classify them as \"Male, evenings only\". Pro tip: with this kind of analysis, you may run a hierarchical cluster analysis to divide the classifications into subgroups.  \n",
    "\n",
    "<u>Dimensionality Reduction</u>  \n",
    "Lets say we find a strong correlation between age of a car and mileage. We can then group them into a specific class titled \"wear and tear\". This is called <u>feature extraction</u>  \n",
    "\n",
    "<u>Anomaly Detection</u>  \n",
    "For example, Credit card fraud. Anomaly Detection will sense for any unusual activity on the card. This method can sometimes be used to remove outliers before feeding more data to another algorithm. \n",
    "\n",
    "<u>Association Rule Learning</u>\n",
    "If you own a supermarket, and this algorithms notices that people that bought charcoal and lighter fluid also tend to buy steaks and ground beef, the system will associate the two. You may then conclude to place the items near each other. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### <strong>Semisupervised Learning</strong>  \n",
    "\n",
    "<u>Use Case:</u> Labelling data can be time consuming and costly, and scientists may have several unlabelled instances. Semisupervised Learning can assist in labelling these unknowns.\n",
    "\n",
    "<u>Example:</u> Google Photos - when someone uploads 10 photos, it may recognize that personA is in photos 1, 7, 10 while personB is in photos 1, 4, 8 (this is an example of <strong>Clustering, Unsupervised Learning</strong>). All one would need to do is label personA on photo 1, and Google Photos will enable <strong>Semisupervised Learning</strong> to label personA in the other photos (photo 7 and 10)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Reinforcement Training\n",
    "\n",
    "<u>Definition:</u> in this algorithm, there is a 'learning system', called an <strong>agent</strong>, that can observe the environment, and select and perform actions. Depending on the output, the system will return rewards or penalties. Once the agent is rewarded (positively or negatively), it decides on the best strategy to choose an action given a certain situation, called a <strong>policy</strong>.\n",
    "\n",
    "<u>Example:</u> DeepMind's AlphaGo program was able to beat the world champion at Go in May 2017. This machine learning algorithm used millions of winning strategies, played itself over and over, until it finally had a win percentage over a certain point."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Batch Learning\n",
    "\n",
    "<u>Definition:</u> in this learning, the system is fed all the data at one time. It is usually under <strong>offline training</strong> due to the amount of time it takes to 'ingest' and learn the data. However, because of this, the system is launched after offline training and is no longer trained afterward. What it learns from the data is what it outputs until the next batched training.\n",
    "\n",
    "Because Batch learning <strong>does not</strong> learn incrementally, everytime the system needs to learn a new feature (i.e. a new type of spam email), the system will need to go offline, the training data must be extracted, then the data of the new feature (i.e. new spam traits) must be added to the old data. Kind of like a cut and paste method with the old data and adding in the new data. The system will need to \"forget\" its past training, and be re-trained on the newly-completed dataset.\n",
    "\n",
    "<u>Precautions:</u> Although the data is easier to manage this way, it is not the most ideal. Batch Learning requires alot of time, inconsistency, and resources (i.e. memory/RAM, CPU, disk space, etc.). It is preferred to use a ML algorithm that uses incremental learning."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Online Learning\n",
    "\n",
    "<u>Definition:</u> train the system incrementally by feeding it data in small batches. Each 'learning' step is fast and cheap, allowing the system to learn on the fly.\n",
    "\n",
    "<strong>Use Cases: </strong> it is best used for data that is continuously flowing (i.e. stock prices). Adapting to change rapidly and autonomously is a key feature with online learning. \n",
    "\n",
    "<strong>Benefits:</strong> Because this method learns autonomously, once it learns from a dataset, it no longer needs that dataset (allowing creators to 'throw' the data, and save memory / disk space). \n",
    "\n",
    "<strong>Cautions: </strong> a parameter that one should heed is the \"learning rate\", or the speed in which the system adapts and learns a new data set. Setting a high learning rate can result in the system forgetting old data. For example, if a system is trained on too much new spam data, it may forget how the older spam data 'looks like'. However, if it learns too slow, the system will be less sensitive to noise in new data or to outliers.\n",
    "\n",
    "Because Online Learning is reliant on the speed of feeding of the data, Online Learning demands more monitoring and attention. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Instance-Based Learning vs. Model-Based Learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Another way to categorize Machine Learning is classifying how they <strong>generalize</strong>\n",
    "\n",
    "Most Machine Learning use cases are on Predictive Analytics and making predictions. So a true test of a Machine Learning application is not by how well it trains with data, but by how well it performs in new instances. \n",
    "\n",
    "There are two main approaches to generalizations: <strong>Instance-Based</strong> vs. <strong>Model-Based</strong>."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Instance-Based Learning\n",
    "\n",
    "<u>Example: </u> instead of relying on spam filters, your filters can be programmed to also flag emails that are very similar to known spam emails. A parameter called 'measure of similarity' can be used between the two emails. For example, perhaps the filter can be programmed to count the number of times a certain word is used in a spam email. If an email were to come into the inbox with the same word counted approximately the same amount of times, it will then label the email as spam. \n",
    "\n",
    "<u>Definition: </u> this is an example of <strong>Instance-Based Learning</strong>. the system learns the examples by heart, then generalizes to new cases by using similarity measures to compare them to the learned examples.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Model-Based Learning\n",
    "\n",
    "<u>Definition: </u> A way of generalizing a set of examples by building a model of the examples and then using that model to make predictions. \n",
    "\n",
    "<u>Example and Project Idea: </u> you want to know if money makes people happy, so you download the OECD's Better Life Index data (https://homl.info/4) and stats about the GDP per capita the IMF's website (https://homl.info/5). \n",
    "\n",
    "Because it looks like life satisfaction increases as GDP per capita increases, you decide the two are positively correlated. So you decide to model <u>life satisfaction as a linear function of GDP per capita</u>.\n",
    "    \n",
    "This method is called <strong>Model Selection</strong>. You selected a linear model of life satisfaction with GDP per capita."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<strong>Implementing the Model-Based Learning: Linear Regression</strong>\n",
    "\n",
    "Linear Regression Formula: y-axis (dependent) = x + y * x-axis (independent)\n",
    "\n",
    "In the GDP Example mentioned above, because happiness is positively correlated to the GDP per capita, we can formulate a linear regression model. \n",
    "\n",
    "We first define the parameter values x and y. There are two approaches to this:  \n",
    "<u>Utility (fitness) Function</u> - measure how good the model is  \n",
    "<u>Cost Function</u> - measure how bad a model is\n",
    "\n",
    "Most Linear Regression problems, people tend to use <u>Cost Function</u> to measure the distance between the predictions and the training samples with the objective to minimize the distance.\n",
    "\n",
    "Next step is to feed the linear regression algorithm. In other words, <strong>train the model</strong>:  \n",
    "Feed the training examples into the linear regression algorithm  \n",
    "The model will find the parameters that make the linear model fit best to the data.  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
